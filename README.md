# ğŸš€ DoorDash Delivery Duration Prediction

> _Predicting accurate food delivery times using real-world order data, machine learning, and MLflow experiment tracking._

## ğŸ§  Project Overview

Accurate delivery time prediction is critical to enhancing customer satisfaction and optimizing operations for online food delivery platforms like __DoorDash__.

In this project, I developed an __end-to-end Machine Learning pipeline__ to predict the __total delivery duration (in seconds)__ â€” i.e., the time from when a customer places an order to when itâ€™s delivered.

The pipeline integrates __data preprocessing, feature engineering, model training, experiment tracking (via MLflow)__, and model evaluation.

## ğŸ¯ Objective

To predict the __total delivery duration__ for a given order using order, store, market, and dasher-related features.

__Target Variable:__
`total_delivery_duration_seconds = actual_delivery_time - created_at`

## ğŸ§© Dataset Description

The dataset (`historical_data.csv`) contains a subset of DoorDash orders from early 2015 with noise added to obfuscate business details.

### Feature Categories

| Category                          | Description                                                                         |
| --------------------------------- | ----------------------------------------------------------------------------------- |
| **Time features**                 | `created_at`, `actual_delivery_time`, `market_id`                                   |
| **Store features**                | `store_id`, `store_primary_category`, `order_protocol`                              |
| **Order features**                | `total_items`, `num_distinct_items`, `subtotal`, `min_item_price`, `max_item_price` |
| **Market features**               | `total_onshift_dashers`, `total_busy_dashers`, `total_outstanding_orders`           |
| **Predictions from other models** | `estimated_order_place_duration`, `estimated_store_to_consumer_driving_duration`    |

## âš™ï¸ Workflow

### 1ï¸âƒ£ Data Preprocessing
- Removed invalid/negative values and handled missing data.
- Applied __log transformation__ to right-skewed variables (e.g., `subtotal`, `total_items`).
- Handled __outliers__ using __winsorization__ to reduce the influence of extreme values.
- Extracted __temporal features__ from `created_at` (hour, weekday, weekend indicator).
- Encoded categorical variables (`store_primary_category`, `market_id`, `order_protocol`).

### 2ï¸âƒ£ Feature Engineering
Created __15+ new features__ to capture operational and temporal insights:
- __Dasher Demand Ratio:__ `total_busy_dashers / total_onshift_dashers`
- __Outstanding Orders per Dasher:__ `total_outstanding_orders / total_onshift_dashers`
- __Order Value Ratios:__ `subtotal / total_items`, `max_item_price / min_item_price`
- __Time of Day Features:__ one-hot encoded hours to capture peak ordering times.

### 3ï¸âƒ£ Modeling
Trained and compared multiple regression models:
- __Linear Regression__
- __Random Forest Regressor__
- __XGBoost Regressor__ 
- __LighGBM__ (best performer)

### 4ï¸âƒ£ MLflow Integration

MLflow was used to __track experiments__, __log metrics__, and __compare model performance__ efficiently.

#### Key Components:

- `mlflow.start_run()` for each experiment.
- Logged parameters: learning rate, n_estimators, max_depth, etc.
- Logged metrics: MAE, RMSE, RÂ².
- Tracked and visualized results on __MLflow UI dashboard__.

__Example:__
```python
with mlflow.start_run(run_name="xgboost_v1"):
    model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=7)
    model.fit(X_train, y_train)
    
    preds = model.predict(X_test)
    mae = mean_absolute_error(y_test, preds)
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    
    mlflow.log_param("n_estimators", 200)
    mlflow.log_metric("MAE", mae)
    mlflow.log_metric("RMSE", rmse)
    mlflow.xgboost.log_model(model, "model")
```
This allowed quick __model-to-model comparisons__ and tracking of tuning progress.

### ğŸ“Š Results
| Metric       | Baseline         | Final (XGBoost + Feature Engg) | Improvement |
| ------------ | ---------------- | ------------------------------ | ----------- |
| **MAE**      | 717 s (~12 min)  | **684 s (~11 min)**            | â†“ 5%        |
| **RMSE**     | 2247 s (~37 min) | **964 s (~16 min)**            | â†“ 57%       |
| **RÂ² Score** | 0.08             | **0.24**                       | +0.16       |

âœ… __XGBoost__ was the best-performing model, balancing accuracy and interpretability.

### ğŸ› ï¸ Tech Stack
| Category                | Tools                                |
| ----------------------- | ------------------------------------ |
| **Languages**           | Python                               |
| **Libraries**           | Pandas, NumPy, Scikit-learn, XGBoost |
| **Visualization**       | Matplotlib, Seaborn                  |
| **Experiment Tracking** | MLflow                               |
| **Version Control**     | Git, GitHub                          |

### ğŸ’¡ Key Learnings

- Handling __real-world noisy operational data__ (negative and skewed distributions).
- Designing __reproducible ML pipelines__ with MLflow for experiment tracking.
- Effective __feature engineering__ significantly boosts model accuracy.
- Balancing __model performance__ with interpretability and reproducibility.

### ğŸš€ Future Enhancements

- ğŸ§­ __Deploy__ model as a REST API using Flask or Streamlit for real-time ETA prediction.
- ğŸ§© Integrate __hyperparameter tuning__ (Optuna or GridSearchCV) with MLflow tracking.
- ğŸ“ˆ Automate data ingestion and model retraining for new data batches.
- ğŸŒ Build an interactive __dashboard__ for visualizing feature importance and predictions.

### ğŸ“‚ Repository Structure
```css
ğŸ“¦ doordash_delivery_prediction
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ historical_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ doordash_prediction.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ mlflow_experiments.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ xgb_model.pkl
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

### ğŸ§¾ Results Summary

âœ… Best Model: XGBoost  
ğŸ¯ RMSE: 964 s  
ğŸ•’ MAE: 684 s  
ğŸ“ˆ RÂ²: 0.24  
ğŸ” Improvement: 55% ETA accuracy boost  
